{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Meli_Challenge_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnTkLpvL/ljYHsv1kIhCVc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanbeleno/meli-challenge-2020/blob/main/Meli_Challenge_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEgVHVKgSZWB"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "[Mercado Libre Data Challenge 2020](https://ml-challenge.mercadolibre.com/) requires to build a ML model to predict the next item to be bought by a user based on his/her history of searches and views.\n",
        "\n",
        "We start by installing the required libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmPve_Bretyi",
        "outputId": "02e99557-d31e-4582-c3f2-66aebf5f6e62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ujson==4.0.1\n",
        "!pip install torch==1.7.0\n",
        "!pip install sentence-transformers==0.3.8\n",
        "!pip install fastprogress==1.0.0\n",
        "!pip install scikit-learn==0.23.2\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ujson==4.0.1 in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (0.7)\n",
            "Requirement already satisfied: sentence-transformers==0.3.8 in /usr/local/lib/python3.6/dist-packages (0.3.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (4.41.1)\n",
            "Requirement already satisfied: transformers<3.4.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (3.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (3.2.5)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (1.7.0+cu101)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (0.8.1rc2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (0.1.94)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (20.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers==0.3.8) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers==0.3.8) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers==0.3.8) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers==0.3.8) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (2.4.7)\n",
            "Requirement already satisfied: fastprogress==1.0.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastprogress==1.0.0) (1.18.5)\n",
            "Collecting scikit-learn==0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2) (1.18.5)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.23.2 threadpoolctl-2.1.0\n",
            "Wed Nov 18 01:59:48 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIK-1_eMWFpd"
      },
      "source": [
        "Make sure you don't get disconected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXIjuMUAWIsq",
        "outputId": "3a4752d5-8087-4dec-ffd3-d51cd1d6014a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXMQ4quYT7MW"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We setup Google Drive to access and write data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ38pMXfPx7m",
        "outputId": "5e7cc7ca-c0c8-4716-d7ea-e4cf6b1c0428",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Setup Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/recursos_colab/meli_challenge_2020/'\n",
        "\n",
        "RAW_TRAIN_DATASET_PATH = f'{root_path}train_dataset.jl.gz'\n",
        "TRAIN_DATASET_PATH = f'{root_path}training_dataset.jl.gz'\n",
        "VALIDATION_DATASET_PATH = f'{root_path}validation_dataset.jl.gz'\n",
        "ITEM_DATA_PATH = f'{root_path}item_data.jl.gz'\n",
        "TEST_DATASET_PATH = f'{root_path}test_dataset.jl.gz'\n",
        "SAMPLE_SUBMISSION_PATH = f'{root_path}sample_submission.csv'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VTFY-zbscgF"
      },
      "source": [
        "Run the code below just once, there is no need to download the files on Google Drive more than once. The files are the item data, sample submission file, test and train dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_T5yf_FiKwO",
        "outputId": "fb88e007-9129-49b3-cf44-c75d27558039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download the files and store them in Google Drive\n",
        "import requests\n",
        "file_urls = {\n",
        "    'test_dataset.jl.gz': 'https://meli-data-challenge.s3.amazonaws.com/2020/test_dataset.jl.gz',\n",
        "    'train_dataset.jl.gz': 'https://meli-data-challenge.s3.amazonaws.com/2020/train_dataset.jl.gz',\n",
        "    'item_data.jl.gz': 'https://meli-data-challenge.s3.amazonaws.com/2020/item_data.jl.gz',\n",
        "    'sample_submission.csv': 'https://meli-data-challenge.s3.amazonaws.com/2020/sample_submission.csv'\n",
        "}\n",
        "\n",
        "# Source: https://stackoverflow.com/q/62285313\n",
        "for file_name in file_urls:\n",
        "  r = requests.get(file_urls[file_name], stream = True)\n",
        "  with open(f'{root_path}{file_name}', \"wb\") as file:\n",
        "      for block in r.iter_content(chunk_size = 1024):\n",
        "          if block:\n",
        "              file.write(block)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9DZcJZLVzMW"
      },
      "source": [
        "## Data exploration\n",
        "\n",
        "The files have a Gzipped JSON Lines format and they use most of the RAM available on Google Colab (12GB), so I decided read the files line by line to save some RAM for model training usage. At this point, I'm only interested on two files: ```item_data.jl.gz``` and ```train_dataset.jl.gz```because they are used to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgaTjgYbZhhg"
      },
      "source": [
        "import gzip\n",
        "import ujson\n",
        "\n",
        "def print_first_lines(file_path, n=3):\n",
        "    \"\"\"Print the frist line of JSON Line file using identation of 4\"\"\"\n",
        "    with gzip.open(file_path,'rt') as f:\n",
        "        for index, line in enumerate(f):\n",
        "            data = ujson.loads(line)\n",
        "            print(ujson.dumps(data, indent=4))\n",
        "            if index >= n-1:\n",
        "              break\n",
        "\n",
        "def blocks(files, size=65536):\n",
        "    while True:\n",
        "        b = files.read(size)\n",
        "        if not b: break\n",
        "        yield b\n",
        "\n",
        "def print_num_lines(file_path):\n",
        "    \"\"\"Count the number of lines in a file\"\"\"\n",
        "    with gzip.open(file_path,'rb') as f:\n",
        "        print(sum(bl.decode().count(\"\\n\") for bl in blocks(f)))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1m0bd5gYied"
      },
      "source": [
        "As we can see below, the training data is structured as a dictionary of purchases, searches and views associated with a item bought. We cannot see searches or purchases on the example below, but we know they exist because is shown on the [documentation](https://ml-challenge.mercadolibre.com/downloads) of the challenge. Also, we want to know the number of lines in this file because it's important to create DataLoader that will help us loading batches of records on training instead of loading all the dataset at the same time. There are ```413163``` lines in this file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT81O5wWYddE",
        "outputId": "3cae9a63-2100-43a5-ff43-a46cf1edb2ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print_first_lines(RAW_TRAIN_DATASET_PATH)\n",
        "print_num_lines(RAW_TRAIN_DATASET_PATH)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"user_history\": [\n",
            "        {\n",
            "            \"event_info\": 1786148,\n",
            "            \"event_timestamp\": \"2019-10-19T11:25:42.444-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1786148,\n",
            "            \"event_timestamp\": \"2019-10-19T11:25:57.487-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": \"RELOGIO SMARTWATCH\",\n",
            "            \"event_timestamp\": \"2019-10-19T11:26:07.063-0400\",\n",
            "            \"event_type\": \"search\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T11:27:26.879-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T11:28:36.558-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T11:28:40.827-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T11:30:42.089-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:51:29.622-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:52:09.281-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:52:41.863-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:54:16.119-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:54:40.629-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:54:57.329-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T22:00:04.577-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-20T10:36:47.525-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-20T10:37:23.202-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-20T10:37:47.699-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-20T19:28:14.619-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-20T19:28:41.646-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        }\n",
            "    ],\n",
            "    \"item_bought\": 1748830\n",
            "}\n",
            "{\n",
            "    \"user_history\": [\n",
            "        {\n",
            "            \"event_info\": 643652,\n",
            "            \"event_timestamp\": \"2019-10-06T18:02:53.893-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": \"DESMAMADEIRA ELETRICA\",\n",
            "            \"event_timestamp\": \"2019-10-07T09:45:29.322-0400\",\n",
            "            \"event_type\": \"search\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1156086,\n",
            "            \"event_timestamp\": \"2019-10-07T09:46:07.960-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": \"DESMAMADEIRA ELETRICA\",\n",
            "            \"event_timestamp\": \"2019-10-07T09:46:17.100-0400\",\n",
            "            \"event_type\": \"search\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": \"DESMAMADEIRA ELETRICA\",\n",
            "            \"event_timestamp\": \"2019-10-07T09:46:19.173-0400\",\n",
            "            \"event_type\": \"search\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1943604,\n",
            "            \"event_timestamp\": \"2019-10-07T09:47:53.958-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": \"DESMAMADEIRA ELETRICA\",\n",
            "            \"event_timestamp\": \"2019-10-07T18:53:20.113-0400\",\n",
            "            \"event_type\": \"search\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 206667,\n",
            "            \"event_timestamp\": \"2019-10-07T18:53:26.670-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": \"DESMAMADEIRA ELETRICA\",\n",
            "            \"event_timestamp\": \"2019-10-07T18:54:36.944-0400\",\n",
            "            \"event_type\": \"search\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1282813,\n",
            "            \"event_timestamp\": \"2019-10-07T18:54:50.998-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 228737,\n",
            "            \"event_timestamp\": \"2019-10-07T18:56:43.678-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 228737,\n",
            "            \"event_timestamp\": \"2019-10-07T19:01:44.718-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 228737,\n",
            "            \"event_timestamp\": \"2019-10-07T19:46:18.382-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        }\n",
            "    ],\n",
            "    \"item_bought\": 228737\n",
            "}\n",
            "{\n",
            "    \"user_history\": [\n",
            "        {\n",
            "            \"event_info\": 248595,\n",
            "            \"event_timestamp\": \"2019-10-01T12:46:03.145-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 248595,\n",
            "            \"event_timestamp\": \"2019-10-01T13:21:50.697-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        }\n",
            "    ],\n",
            "    \"item_bought\": 1909110\n",
            "}\n",
            "413162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFzY_3XDZNAK"
      },
      "source": [
        "When the event type on the user history is a view or a purchase, then we have an ```event_info``` associated with an ```item_id``` on the file ```item_data.jl.gz``` that has the following information:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfccTW_5Q_Pw",
        "outputId": "70155751-429e-4db9-fff7-478affe991b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print_first_lines(ITEM_DATA_PATH)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"item_id\": 111260,\n",
            "    \"title\": \"Casa Sola En Venta Con Gran Patio Solo Pago De Contado.\",\n",
            "    \"domain_id\": \"MLM-INDIVIDUAL_HOUSES_FOR_SALE\",\n",
            "    \"product_id\": null,\n",
            "    \"price\": \"1150000.00\",\n",
            "    \"category_id\": \"MLM170527\",\n",
            "    \"condition\": \"new\"\n",
            "}\n",
            "{\n",
            "    \"item_id\": 871377,\n",
            "    \"title\": \"Resident Evil Origins Collection Nintendo Switch (en D3gamer\",\n",
            "    \"domain_id\": \"MLM-VIDEO_GAMES\",\n",
            "    \"product_id\": \"15270800\",\n",
            "    \"price\": \"1392.83\",\n",
            "    \"category_id\": \"MLM151595\",\n",
            "    \"condition\": \"new\"\n",
            "}\n",
            "{\n",
            "    \"item_id\": 490232,\n",
            "    \"title\": \"Falda De Imitaci\\u00f3n Piel Negra\",\n",
            "    \"domain_id\": \"MLM-SKIRTS\",\n",
            "    \"product_id\": null,\n",
            "    \"price\": \"350.00\",\n",
            "    \"category_id\": \"MLM7697\",\n",
            "    \"condition\": \"new\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-niKRTMqazOu"
      },
      "source": [
        "## Preparing the dataset\n",
        "\n",
        "We structure the item data in a dictionary to access that info faster to augment the Dataset Loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVqakmtuxnbe"
      },
      "source": [
        "import gzip\n",
        "import ujson\n",
        "\n",
        "item_details = {}\n",
        "with gzip.open(ITEM_DATA_PATH,'rt') as f:\n",
        "    for index, line in enumerate(f):\n",
        "        data = ujson.loads(line)\n",
        "        item_id = data['item_id']\n",
        "        item_details[item_id] = data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTXUJ_cU9Oun"
      },
      "source": [
        "The first thing I need to do is to split the train dataset between validation and training set. This allows me to fine tune the model without submitting it to the platform each time. The submissions per day are limited to 3 so I prefer to validate my model before submission. In this process, I'm going to delete the item of categories that only have one sample to reduce the complexity of the problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4TAuvnK9aWd",
        "outputId": "36a6e579-1136-4550-f070-e26596c29e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import ujson\n",
        "import random\n",
        "import math\n",
        "\n",
        "\n",
        "def write_dataset(lines, file_path):\n",
        "  with gzip.open(file_path, 'wt') as f:\n",
        "      for index, line in enumerate(lines):\n",
        "          new_line = line.strip(' \\n\\r\\t')\n",
        "          if index == 0:\n",
        "              f.write(new_line)\n",
        "          else:\n",
        "              f.write(f'\\n{new_line}')\n",
        "\n",
        "# We create a dictionary associating domains with their frequency on the\n",
        "# training set\n",
        "classes = []\n",
        "with gzip.open(RAW_TRAIN_DATASET_PATH,'rt') as f:\n",
        "    classes = [item_details[ujson.loads(x)['item_bought']]['domain_id'] for x in f.readlines()]\n",
        "domain_counter = Counter(classes)\n",
        "\n",
        "lines = []\n",
        "classes = []\n",
        "with gzip.open(RAW_TRAIN_DATASET_PATH,'rt') as f:\n",
        "    for line in f:\n",
        "        data = ujson.loads(line)\n",
        "        item_bought = data['item_bought']\n",
        "        domain_id = item_details[item_bought]['domain_id']\n",
        "        if domain_counter[domain_id] > 1:\n",
        "            lines.append(line)\n",
        "            classes.append(domain_id)\n",
        "\n",
        "# Order randomlly the data to improve the SGD on the model\n",
        "train_lines, val_lines = train_test_split(\n",
        "    lines, test_size=0.1, stratify=classes, shuffle=True, random_state=42)\n",
        "\n",
        "write_dataset(train_lines, TRAIN_DATASET_PATH)\n",
        "write_dataset(val_lines, VALIDATION_DATASET_PATH)\n",
        "\n",
        "NUM_TRAINING_SAMPLES = len(train_lines)\n",
        "NUM_VALIDATION_SAMPLES = len(val_lines)\n",
        "print(f'Number of lines for training: {NUM_TRAINING_SAMPLES}')\n",
        "print(f'Number of lines for validation: {NUM_VALIDATION_SAMPLES}')\n",
        "\n",
        "train_lines = None\n",
        "val_lines = None"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of lines for training: 371507\n",
            "Number of lines for validation: 41279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwRfaHQbQOw0"
      },
      "source": [
        "NUM_TRAINING_SAMPLES = 371507\n",
        "NUM_VALIDATION_SAMPLES = 41279"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf_9WGjiAkXc"
      },
      "source": [
        "Based on the idea that possibly not all the items in the set of item_details were bought in the training dataset. I will predict only the items and domains that appear in the training dataset. At the same time, I'm going to get some stats about the distribution of domains in the training set to know how oversample the minority of domains.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u954dcecBXpY"
      },
      "source": [
        "import gzip\n",
        "import ujson\n",
        "\n",
        "domain_map = {}\n",
        "categories_map = {}\n",
        "reduced_feature_map = {}\n",
        "domain_freq = {}\n",
        "top_items_per_domain = {}\n",
        "with gzip.open(TRAIN_DATASET_PATH,'rt') as f:\n",
        "  for line in f:\n",
        "    record = ujson.loads(line)\n",
        "    item_id = record['item_bought']\n",
        "    item = item_details[item_id]\n",
        "    domain_id = item['domain_id']\n",
        "    category_id = item['category_id']\n",
        "\n",
        "    # Find the number of times a domain appears on the training set\n",
        "    domain_freq[domain_id] = domain_freq.get(domain_id, 0) + 1\n",
        "\n",
        "    # Map domains to integers\n",
        "    if domain_id not in domain_map:\n",
        "      domain_map[domain_id] = len(domain_map)\n",
        "\n",
        "    # Map categories to integers\n",
        "    if category_id not in categories_map:\n",
        "      categories_map[category_id] = len(categories_map)\n",
        "\n",
        "    # Creating the dependencies in the prediction\n",
        "    if domain_id not in reduced_feature_map:\n",
        "      reduced_feature_map[domain_id] = {}\n",
        "    if item_id not in reduced_feature_map[domain_id]:\n",
        "      reduced_feature_map[domain_id][item_id] = len(reduced_feature_map[domain_id])\n",
        "    \n",
        "    # Finding the most bought items per domain\n",
        "    if domain_map[domain_id] not in top_items_per_domain:\n",
        "      top_items_per_domain[domain_map[domain_id]] = {}\n",
        "    top_items_per_domain[domain_map[domain_id]][item_id] = top_items_per_domain[domain_map[domain_id]].get(item_id, 0) + 1\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VvzIXInFGkM",
        "outputId": "496af5b1-9205-412e-93fc-21ee5d45c52a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'Items size: {len(item_details)}')\n",
        "print(f'Domains size: {len(domain_map)}')\n",
        "print(f'Categories size: {len(categories_map)}')\n",
        "features_sizes = [len(reduced_feature_map[domain]) for domain in reduced_feature_map]\n",
        "print(f'Min Features: {min(features_sizes)}')\n",
        "print(f'Max Features: {max(features_sizes)}')\n",
        "print(f'Average Features: {sum(features_sizes)/len(features_sizes)}')\n",
        "sorted_freqs = {k: v for k, v in sorted(domain_freq.items(), key=lambda item: item[1], reverse=False)}\n",
        "print(list(sorted_freqs.keys())[:5])\n",
        "print(list(sorted_freqs.values())[:25])\n",
        "\n",
        "NUM_ITEMS_PER_DOMAIN = max(features_sizes)\n",
        "NUM_DOMAINS = len(domain_map)\n",
        "NUM_CATEGORIES = len(categories_map)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Items size: 2102277\n",
            "Domains size: 2837\n",
            "Categories size: 3615\n",
            "Min Features: 1\n",
            "Max Features: 2513\n",
            "Average Features: 22.058160028198802\n",
            "['MLM-AUTOMOTIVE_MANUAL_TRANSMISSION_SHIFT_LEVERS', 'MLM-MEGAPHONES', 'MLB-GPS_CASES_AND_COVERS', 'MLM-MOTORCYCLE_INTERCOMMUNICATORS', 'MLB-SCHOOL_AND_OFFICE_ENVELOPES']\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zz1TvQ0VGtl"
      },
      "source": [
        "Find the percentile 75% for domains to know how many samples need to be oversampled for domains with less than that threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXTSFigoV1Md",
        "outputId": "a9c80eb9-d764-4ab0-ce3d-6fab9b323f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "freq_values = list(domain_freq.values())\n",
        "freq_values.sort()\n",
        "percentile = freq_values[math.ceil(len(freq_values)*75/100)]\n",
        "print(f'P_75: {percentile}')\n",
        "\n",
        "plt.hist(freq_values, bins=100, range=(0, 500))\n",
        "plt.title(\"Histogram\")\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P_75: 55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEUrMjDpyePX"
      },
      "source": [
        "**Dataset Loader:** The dataset loader provides the following features:\n",
        "* The average of the sentence embeddings for item titles for views\n",
        "* The average of the sentence embeddings for searches\n",
        "* A sparse matrix showing the count of domains that appears on views\n",
        "\n",
        "The possible targets for the models are item identifiers, domain numerical identifiers, and categories numerical identifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULJDoAHlcZ5L",
        "outputId": "2037d4f0-8c0f-4c57-edd4-906a1acc5db7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Ideas:\n",
        "# Use the dataset without oversampling\n",
        "from torch.utils.data import Dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import gzip\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import ujson\n",
        "#torch.multiprocessing.set_start_method('spawn')# good solution !!!!\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device: {device}')\n",
        "\n",
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, file_path, config):\n",
        "        self.file_path = file_path\n",
        "        self.config = config\n",
        "        self.sentence_model = SentenceTransformer('average_word_embeddings_glove.6B.300d')\n",
        "        self.sentence_model = self.sentence_model.to(device)\n",
        "        self.f = gzip.open(self.file_path, 'r')\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.config['data_size']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Getting and preprocessing the inputs\"\"\"\n",
        "        if idx == 0:\n",
        "            # Each time a epoch starts, we close the file, open it again, and\n",
        "            # seek the first line just to be sure it starts at the beginning of\n",
        "            # the file\n",
        "            self.f.close()\n",
        "            self.f = gzip.open(self.file_path, 'r')\n",
        "            self.f.seek(0)\n",
        "        response = {}\n",
        "\n",
        "        # Read the line in the file and transform it in JSON\n",
        "        line = self.f.readline()\n",
        "        try:\n",
        "            raw_data = ujson.loads(line)\n",
        "        except:\n",
        "            # Sometimes the connection to the file closes unexpectedly, so we\n",
        "            # handle that problem here\n",
        "            self.f.close()\n",
        "            self.f = gzip.open(self.file_path, 'r')\n",
        "            self.f.seek(0)\n",
        "            for i in range(idx + 1):\n",
        "                line = self.f.readline()\n",
        "            raw_data = ujson.loads(line)\n",
        "\n",
        "        # Identify the historic of a user and the item bought if exist\n",
        "        # We are going to use the same Data Loader for the test dataset, which\n",
        "        # does not have 'item_bought'\n",
        "        user_history = self.normalize_user_history(raw_data['user_history'])\n",
        "        item_bought = None\n",
        "        if 'item_bought' in raw_data:\n",
        "            item_bought = raw_data['item_bought']\n",
        "\n",
        "        views = []\n",
        "        searches = []\n",
        "        # The embedding size produced by DISTILLBERT is 768. GloVe embeddings\n",
        "        # have 300 dimensions. DISTILLBERT embeddings are more useful than the\n",
        "        # ones produced by GloVe, but they take like 6 times more of computing\n",
        "        # time.\n",
        "        #embedding_size = 768\n",
        "        embedding_size = 300\n",
        "\n",
        "        # By default, we fill the embeddings with zeros\n",
        "        avg_view_embeddings = np.zeros(embedding_size)\n",
        "        avg_search_embeddings = np.zeros(embedding_size)\n",
        "        category_embeddings = np.zeros(NUM_CATEGORIES)\n",
        "        domain_embeddings = np.zeros(NUM_DOMAINS)\n",
        "        price_embedding = np.zeros(5)\n",
        "        condition_embedding = np.zeros(2)\n",
        "\n",
        "        if len(user_history) > 0:\n",
        "            prices = []\n",
        "            # First position are the new items and the second position is for\n",
        "            # second had items\n",
        "            conditions = [0,0]\n",
        "            for item in user_history:\n",
        "                # Iterate over the items in the user_history and find the text\n",
        "                # in searches or extract the item titles for views.\n",
        "                if item['event_type'] == 'search':\n",
        "                    text = item['event_info']\n",
        "                    searches.append(text)\n",
        "                else:\n",
        "                    # Find the domains that appear on the views\n",
        "                    domain_id = item_details[item['event_info']]['domain_id']\n",
        "                    if domain_id in domain_map:\n",
        "                        domain_embeddings[domain_map[domain_id]] = domain_embeddings[domain_map[domain_id]] + 1\n",
        "                    \n",
        "                    # Find the categories that appear on the views\n",
        "                    category_id = item_details[item['event_info']]['category_id']\n",
        "                    if category_id in categories_map:\n",
        "                        category_embeddings[categories_map[category_id]] = category_embeddings[categories_map[category_id]] + 1\n",
        "\n",
        "                    # Include all the prices of items of views\n",
        "                    price = item_details[item['event_info']]['price']\n",
        "                    if price:\n",
        "                        price = float(price)\n",
        "                        prices.append(price)\n",
        "\n",
        "                    # Include the item condition\n",
        "                    condition = item_details[item['event_info']]['condition']\n",
        "                    if condition == 'new':\n",
        "                        conditions[0] = conditions[0] + 1\n",
        "                    else:\n",
        "                        conditions[1] = conditions[1] + 1\n",
        "\n",
        "                    text = item_details[item['event_info']]['title']\n",
        "                    views.append(text)\n",
        "\n",
        "            # If there are prices, then calculate a simple embedding using\n",
        "            # cumulative metrics like min, max, mean, median, standard deviation\n",
        "            if len(prices) > 0:\n",
        "                prices = np.array(prices)\n",
        "                price_embedding[0] = np.min(prices)\n",
        "                price_embedding[1] = np.max(prices)\n",
        "                price_embedding[2] = np.nanmedian(prices)\n",
        "                price_embedding[3] = np.nanmean(prices)\n",
        "                price_embedding[4] = np.nanstd(prices)\n",
        "            \n",
        "            # If there are conditions for items, then normalize the list\n",
        "            if sum(conditions) > 0:\n",
        "                conditions = np.array(conditions)\n",
        "                condition_embedding[0] = conditions[0] / np.sum(conditions)\n",
        "                condition_embedding[1] = conditions[1] / np.sum(conditions)\n",
        "\n",
        "            # If there are views, then calculate the view embeddings from the\n",
        "            # item title on the views\n",
        "            if len(views) > 0:\n",
        "              view_embeddings = self.sentence_model.encode(views)\n",
        "              avg_view_embeddings = self.embeddings_weighted_average(view_embeddings)\n",
        "\n",
        "            # If there are searches, the calculate the search embeddings from them\n",
        "            if len(searches) > 0:\n",
        "              search_embeddings = self.sentence_model.encode(searches)\n",
        "              avg_search_embeddings = self.embeddings_weighted_average(search_embeddings)\n",
        "\n",
        "        # Assign the values to the features\n",
        "        response['view_embeddings'] = avg_view_embeddings\n",
        "        response['search_embeddings'] = avg_search_embeddings\n",
        "        response['domain_embeddings'] = domain_embeddings\n",
        "        response['category_embeddings'] = category_embeddings\n",
        "        response['price_embedding'] = price_embedding\n",
        "        response['condition_embedding'] = condition_embedding\n",
        "\n",
        "        # If we are handling the training or validation set, then we also get\n",
        "        # the domain, category and item identifiers\n",
        "        if item_bought:\n",
        "            item_data = item_details[item_bought]\n",
        "            domain_id = item_data['domain_id']\n",
        "            category_id = item_data['category_id']\n",
        "\n",
        "            # We need to verify the values for targets because some items,\n",
        "            # domains, and categories can appear on the trainig set but not\n",
        "            # on the validation set\n",
        "            domain_map_id = NUM_DOMAINS\n",
        "            category_map_id = NUM_CATEGORIES\n",
        "            item_map_id = NUM_ITEMS_PER_DOMAIN\n",
        "            if domain_id in domain_map:\n",
        "                domain_map_id = domain_map[domain_id]\n",
        "                if item_bought in reduced_feature_map.get(domain_id, {}):\n",
        "                    item_map_id = reduced_feature_map[domain_id][item_bought]\n",
        "            if category_id in categories_map:\n",
        "                category_map_id = categories_map[category_id]\n",
        "\n",
        "            # Set the value for the targets\n",
        "            response['item'] = torch.tensor(\n",
        "                item_map_id, dtype=torch.long)\n",
        "            response['domain'] = torch.tensor(\n",
        "                domain_map_id, dtype=torch.long)\n",
        "            response['category'] = torch.tensor(\n",
        "                category_map_id, dtype=torch.long)\n",
        "        return response\n",
        "\n",
        "    def normalize_user_history(sefl, user_history):\n",
        "      # Remove duplicated views and searches that appear almost at the same time\n",
        "      new_user_history = []\n",
        "      last_item_id = ''\n",
        "      for item in user_history:\n",
        "        current_item_id = item['event_info']\n",
        "        if current_item_id != last_item_id:\n",
        "          new_user_history.append(item)\n",
        "        last_item_id = current_item_id\n",
        "      # We are only going to consider the last 30 events\n",
        "      return new_user_history[-30:]\n",
        "\n",
        "    def embeddings_weighted_average(self, embeddings):\n",
        "      # I'm going to use a logarithmic decrease in the importance of each\n",
        "      # view or search according to its recency\n",
        "      embeddings_size = embeddings.shape[0]\n",
        "      avg_embeddings = embeddings\n",
        "      if embeddings_size >= 1:\n",
        "        weights = [1.0 / math.log2(2 + index) for index in range(embeddings_size)]\n",
        "        normal_weigths = [float(w)/sum(weights) for w in weights]\n",
        "        # The last item in the embeddings is the most recent\n",
        "        normal_weigths = np.array(list(reversed(normal_weigths)))\n",
        "        avg_embeddings = embeddings * normal_weigths.reshape((normal_weigths.size, 1))\n",
        "        avg_embeddings = np.sum(avg_embeddings, axis=0)\n",
        "      return avg_embeddings\n",
        "        \n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddlnU955UH_1"
      },
      "source": [
        "Get the data loader for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00zSkp9YUJ2U"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def my_train_collate(batch):\n",
        "    '''Get features and targets'''\n",
        "    # Features\n",
        "    searches = torch.from_numpy(np.array([item['search_embeddings'] for item in batch]))\n",
        "    views = torch.from_numpy(np.array([item['view_embeddings'] for item in batch]))\n",
        "    domain_views = torch.from_numpy(np.array([item['domain_embeddings'] for item in batch]))\n",
        "    categories = torch.from_numpy(np.array([item['category_embeddings'] for item in batch]))\n",
        "    prices = torch.from_numpy(np.array([item['price_embedding'] for item in batch]))\n",
        "    conditions = torch.from_numpy(np.array([item['condition_embedding'] for item in batch]))\n",
        "\n",
        "    # Targets\n",
        "    items = [item['item'] for item in batch]\n",
        "    items = torch.LongTensor(items)\n",
        "    domains = [item['domain'] for item in batch]\n",
        "    domains = torch.LongTensor(domains)\n",
        "    return {\n",
        "        'searches': searches,\n",
        "        'views': views,\n",
        "        'domain_views': domain_views,\n",
        "        'categories': categories,\n",
        "        'prices': prices,\n",
        "        'conditions': conditions,\n",
        "        'items': items,\n",
        "        'domains': domains\n",
        "    }\n",
        "\n",
        "# Get the Dataset Loader for training\n",
        "training_config = {\n",
        "    'data_size': NUM_TRAINING_SAMPLES,\n",
        "    'batch_size': BATCH_SIZE\n",
        "}\n",
        "ds_train = MultiTaskDataset(TRAIN_DATASET_PATH, training_config)\n",
        "training_loader = DataLoader(\n",
        "    ds_train, batch_size=BATCH_SIZE, num_workers=0, collate_fn=my_train_collate,\n",
        "    pin_memory=True, shuffle=True)\n",
        "\n",
        "# Get the Dataset Loader for validation\n",
        "validation_config = {\n",
        "    'data_size': NUM_VALIDATION_SAMPLES,\n",
        "    'batch_size': BATCH_SIZE\n",
        "}\n",
        "ds_val = MultiTaskDataset(VALIDATION_DATASET_PATH, validation_config)\n",
        "validation_loader = DataLoader(\n",
        "    ds_val, batch_size=BATCH_SIZE, num_workers=0, collate_fn=my_train_collate,\n",
        "    pin_memory=True, shuffle=True)\n",
        "\n",
        "# Notes:\n",
        "# * I found a buggy behavior when num_workers != 0, then I set it that way.\n",
        "# * pin_memory is True to save some memory and speed up the training process.\n",
        "# * shuffle is True to give a little bit of randomness each epoch"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65wVy5Fs_WQr"
      },
      "source": [
        "## Creating the model\n",
        "\n",
        "The model is the ```bert-case-uncased``` version of BERT provided by HugginFaces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LymDLqH_yyG"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Creates a MultiTask model for classifications of domains and items based on\n",
        "    the same text\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #num_items = 2102277\n",
        "        num_items_per_domain = NUM_ITEMS_PER_DOMAIN\n",
        "        num_domains = NUM_DOMAINS\n",
        "        num_categories = NUM_CATEGORIES\n",
        "\n",
        "        # The embedding size produced by DISTILLBERT is 768. GloVe embeddings\n",
        "        # have 300 dimensions. DISTILLBERT embeddings are more useful than the\n",
        "        # ones produced by GloVe, but they take like 6 times more of computing\n",
        "        # time.\n",
        "        #embedding_size = 768\n",
        "        embedding_size = 300\n",
        "\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        #self.dropout = nn.Dropout(0.1)\n",
        "        self.hidden_1 = nn.Linear(embedding_size*2 + num_domains + num_categories + 5 + 2, 512)\n",
        "        self.hidden_1_relu = nn.ReLU()\n",
        "        self.hidden_2 = nn.Linear(512, 256)\n",
        "        self.hidden_2_relu = nn.ReLU()\n",
        "\n",
        "        # Output layers\n",
        "        self.output_domains = nn.Linear(256, num_domains)\n",
        "        self.output_items = nn.Linear(256, num_items_per_domain)\n",
        "\n",
        "        # Define the softmax output\n",
        "        self.log_softmax_domains = nn.LogSoftmax(dim=1)\n",
        "        self.log_softmax_items = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, views, searches, domain_views, categories, prices, conditions):\n",
        "        # Pass the input tensor through each of our operations\n",
        "        inputs = torch.cat(\n",
        "            (views, searches, domain_views, categories, prices, conditions), dim=1)\n",
        "        #x = self.dropout(inputs)\n",
        "        x = self.hidden_1(inputs)\n",
        "        x = self.hidden_1_relu(x)\n",
        "        x = self.hidden_2(x)\n",
        "        x = self.hidden_2_relu(x)\n",
        "\n",
        "        x_domains = self.output_domains(x)\n",
        "        y_domains = self.log_softmax_domains(x_domains)\n",
        "\n",
        "        x_items = self.output_items(x)\n",
        "        y_items = self.log_softmax_items(x_items)\n",
        "\n",
        "        return y_domains, y_items"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_tQfQHdI2qg"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_YqJolvGR3p"
      },
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def get_feature_map(reduced_feature_map, domain_map):\n",
        "    features_map = {}\n",
        "    for domain in reduced_feature_map:\n",
        "        for item in reduced_feature_map[domain]:\n",
        "            domain_id = domain_map[domain]\n",
        "            item_id = reduced_feature_map[domain][item]\n",
        "\n",
        "            if domain_id not in features_map:\n",
        "                features_map[domain_id] = {}\n",
        "            if item_id not in features_map[domain_id]:\n",
        "                features_map[domain_id][item_id] = item\n",
        "    return features_map\n",
        "\n",
        "features_map = get_feature_map(reduced_feature_map, domain_map)\n",
        "\n",
        "def get_metric(d_predictions, i_predictions, items, domains):\n",
        "    num_correct = 0\n",
        "    for index, domain in enumerate(d_predictions.tolist()):\n",
        "        candidates = []\n",
        "        true_item = None\n",
        "        true_domain = int(domains[index].data)\n",
        "        if true_domain == domain:\n",
        "            true_item_id = int(items[index].data)\n",
        "            if true_item_id in features_map[domain]:\n",
        "                true_item = features_map[domain][true_item_id]\n",
        "            default_item = list(features_map[domain].values())[0]\n",
        "            for item_candidate in i_predictions[index]:\n",
        "                item_id = features_map[domain].get(item_candidate, None)\n",
        "                if item_id and len(candidates) < 10:\n",
        "                    candidates.append(item_id)\n",
        "            candidates.extend([default_item] * (10 - len(candidates)))\n",
        "\n",
        "        if (len(candidates) > 0) and (true_item in candidates):\n",
        "            index_find = candidates.index(true_item)\n",
        "            numerator = sum([12 / math.log(2 + x) if x == index_find else 1 / math.log(2 + x) for x in range(10)])\n",
        "            denominator = sum([12 / math.log(2 + x) if x == 0 else 1 / math.log(2 + x) for x in range(10)])\n",
        "            num_correct += numerator * 1.0 / denominator\n",
        "        elif len(candidates) > 0:\n",
        "            numerator = sum([1 / math.log(2 + x) for x in range(10)])\n",
        "            denominator = sum([12 / math.log(2 + x) if x == 0 else 1 / math.log(2 + x) for x in range(10)])\n",
        "            num_correct += numerator * 1.0 / denominator\n",
        "        else:\n",
        "            num_correct += 0\n",
        "    return num_correct\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ctQRdTdB9za",
        "outputId": "3a49ac1f-0caf-4057-a0ba-67e0c3cc1b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from fastprogress import master_bar, progress_bar\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "\n",
        "\n",
        "# Define model and let it use the GPU\n",
        "MODEL_PATH = f'{root_path}model-10.pth'\n",
        "model = MultiTaskModel()\n",
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss for multi-task classification and let it use the GPU\n",
        "criterion = [nn.NLLLoss(), nn.NLLLoss()]\n",
        "criterion[0] = criterion[0].to(device)\n",
        "criterion[1] = criterion[1].to(device)\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "# After the second epoch, the loss does not vary much and I just need to know\n",
        "# what combination of features + model is the best, so I prefer to user the\n",
        "# minimum resources available\n",
        "epochs = 4\n",
        "mb = master_bar(range(epochs))\n",
        "\n",
        "for epoch in mb:\n",
        "    print(f'Epoch: {epoch}')\n",
        "    print('-' * 10)\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Training phase\n",
        "    # ----------------\n",
        "    model.train()\n",
        "    for record in progress_bar(training_loader, parent=mb):\n",
        "        # Transform features and target to use the GPU\n",
        "        views = record['views'].to(device)\n",
        "        searches = record['searches'].to(device)\n",
        "        domain_views = record['domain_views'].to(device)\n",
        "        categories = record['categories'].to(device)\n",
        "        prices = record['prices'].to(device)\n",
        "        conditions = record['conditions'].to(device)\n",
        "\n",
        "        items = record['items'].to(device)\n",
        "        domains = record['domains'].to(device)\n",
        "\n",
        "        # Reset the optimizer: Don't reuse info about the last batches\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output_domains, output_items = model(\n",
        "            views.float(), searches.float(), domain_views.float(),\n",
        "            categories.float(), prices.float(), conditions.float())\n",
        "        loss_items = criterion[0](output_items, items)\n",
        "        loss_domains = criterion[0](output_domains, domains)\n",
        "        loss = loss_items + loss_domains\n",
        "        #loss = loss_domains\n",
        "\n",
        "        # backward + optimize only if the model is in training phase\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(training_loader)}\")\n",
        "\n",
        "    # Validation phase\n",
        "    # ----------------\n",
        "    model.eval()\n",
        "    num_correct_domains = 0\n",
        "    num_samples_domains = 0\n",
        "    num_correct_items = 0\n",
        "    num_samples_items = 0\n",
        "    with torch.no_grad():\n",
        "        for record in progress_bar(validation_loader, parent=mb):\n",
        "            # Prepare features to use the GPU\n",
        "            views = record['views'].to(device)\n",
        "            searches = record['searches'].to(device)\n",
        "            domain_views = record['domain_views'].to(device)\n",
        "            categories = record['categories'].to(device)\n",
        "            prices = record['prices'].to(device)\n",
        "            conditions = record['conditions'].to(device)\n",
        "\n",
        "            domains = record['domains'].to(device)\n",
        "            items = record['items'].to(device)\n",
        "\n",
        "            # Get the predictions\n",
        "            p_domains, p_items = model(\n",
        "                views.float(), searches.float(), domain_views.float(),\n",
        "                categories.float(), prices.float(), conditions.float())\n",
        "            _, d_predictions = p_domains.max(1)\n",
        "            _, i_predictions = torch.topk(p_items, 50)\n",
        "\n",
        "            # Get metrics\n",
        "            num_correct_items += get_metric(d_predictions, i_predictions, items, domains)\n",
        "            num_samples_items += d_predictions.size(0)\n",
        "\n",
        "            num_correct_domains += (d_predictions == domains).sum()\n",
        "            num_samples_domains += d_predictions.size(0)\n",
        "        print(f'Got {num_correct_domains} / {num_samples_domains} with accuracy {float(num_correct_domains)/float(num_samples_domains)*100:.2f}')\n",
        "        print(f'Got {num_correct_items} / {num_samples_items} with DCG {float(num_correct_items)/float(num_samples_items):.2f}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "----------\n",
            "Training loss: 678.9540454310861\n",
            "Got 4820 / 41279 with accuracy 11.68\n",
            "Got 1447.1560548211153 / 41279 with DCG 0.04\n",
            "Epoch: 1\n",
            "----------\n",
            "Training loss: 16.787153975251005\n",
            "Got 7799 / 41279 with accuracy 18.89\n",
            "Got 2358.997606674342 / 41279 with DCG 0.06\n",
            "Epoch: 2\n",
            "----------\n",
            "Training loss: 17.046747474440412\n",
            "Got 8554 / 41279 with accuracy 20.72\n",
            "Got 2605.8771801870507 / 41279 with DCG 0.06\n",
            "Epoch: 3\n",
            "----------\n",
            "Training loss: 12.877940181696035\n",
            "Got 9423 / 41279 with accuracy 22.83\n",
            "Got 2890.326383141776 / 41279 with DCG 0.07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7sbHHNbaIAT"
      },
      "source": [
        "Let's define where to store the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfx3fG-3ZvcD"
      },
      "source": [
        "import torch\n",
        "\n",
        "MODEL_PATH = f'{root_path}model-10.pth'"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmlJ5bRpjiXu"
      },
      "source": [
        "Let's store the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9hwJzivjVCu"
      },
      "source": [
        "torch.save(model.state_dict(), MODEL_PATH)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "635LO4z7ZYBX"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "Before sending the answer to this challenge, we need to see the format for the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am8ROroUdvF4",
        "outputId": "b695d715-2602-42c8-94dd-415e00ee2036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with open(SAMPLE_SUBMISSION_PATH,'rt') as f:\n",
        "    for index, line in enumerate(f):\n",
        "        if index < 4:\n",
        "            print(line)\n",
        "print(f'Number of lines: {index + 1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "654238,781750,558980,663439,1397720,1095079,798751,1141944,411021,138117\n",
            "\n",
            "462167,1511283,928291,1907892,66135,54134,1090655,700291,63494,613724\n",
            "\n",
            "2092880,1974491,1687910,371918,1659351,156119,578171,1407298,1378300,500637\n",
            "\n",
            "614011,509284,181629,1544217,267392,409673,755307,1621679,767644,617841\n",
            "\n",
            "Number of lines: 177070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUoAvkq0exYP"
      },
      "source": [
        "If Google Colab closed the connection before testing, we can get the model from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvJOlnbnk_BA"
      },
      "source": [
        "# Optional\n",
        "model = MultiTaskModel()\n",
        "model.load_state_dict(torch.load(MODEL_PATH))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GdLcHZgkQdh"
      },
      "source": [
        "We define the Data Loader for the testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG47EfVHZ_Hc"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "NUM_TESTING_SAMPLES = 177070\n",
        "\n",
        "def my_test_collate(batch):\n",
        "    \"\"\"Get only the features because for testing we have to produce the targets\"\"\"\n",
        "    searches = torch.from_numpy(np.array([item['search_embeddings'] for item in batch]))\n",
        "    views = torch.from_numpy(np.array([item['view_embeddings'] for item in batch]))\n",
        "    domain_views = torch.from_numpy(np.array([item['domain_embeddings'] for item in batch]))\n",
        "    categories = torch.from_numpy(np.array([item['category_embeddings'] for item in batch]))\n",
        "    prices = torch.from_numpy(np.array([item['price_embedding'] for item in batch]))\n",
        "    conditions = torch.from_numpy(np.array([item['condition_embedding'] for item in batch]))\n",
        "    return {\n",
        "        'searches': searches,\n",
        "        'views': views,\n",
        "        'domain_views': domain_views,\n",
        "        'categories': categories,\n",
        "        'prices': prices,\n",
        "        'conditions': conditions\n",
        "    }\n",
        "\n",
        "test_config = {\n",
        "    'data_size': NUM_TESTING_SAMPLES,\n",
        "    'batch_size': BATCH_SIZE\n",
        "}\n",
        "ds_test = MultiTaskDataset(TEST_DATASET_PATH, test_config)\n",
        "test_loader = DataLoader(\n",
        "    ds_test, batch_size=BATCH_SIZE, num_workers=0, collate_fn=my_test_collate,\n",
        "    pin_memory=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwPdM4cslVNH"
      },
      "source": [
        "Get the predictions for domains and fill the item identifiers with the most popular items per domain. If there is only one item in a domain repeat it until get the necessary 10 items per record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcJEFFrkbHdk"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "def get_predictions(model, data_loader):\n",
        "    \"\"\"Get item identifiers that the user will probably buy\"\"\"\n",
        "    model = model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for record in test_loader:\n",
        "            # Prepare features to use the GPU\n",
        "            views = record['views'].to(device)\n",
        "            searches = record['searches'].to(device)\n",
        "            domain_views = record['domain_views'].to(device)\n",
        "            categories = record['categories'].to(device)\n",
        "            prices = record['prices'].to(device)\n",
        "            conditions = record['conditions'].to(device)\n",
        "\n",
        "            # Get the predictions\n",
        "            domains, items = model(\n",
        "                views.float(), searches.float(), domain_views.float(),\n",
        "                categories.float(), prices.float(), conditions.float())\n",
        "            _, preds_items = torch.topk(items, 50)\n",
        "            _, preds_domains = torch.max(domains, dim=1)\n",
        "\n",
        "            # Fill the items from the domain predicted up to 10 items per prediction\n",
        "            preds = []\n",
        "            for index, domain in enumerate(preds_domains.tolist()):\n",
        "                default_item = list(features_map[domain].values())[0]\n",
        "                subset_items = []\n",
        "                for item_candidate in preds_items[index]:\n",
        "                    item_id = features_map[domain].get(item_candidate, None)\n",
        "                    if item_id and len(subset_items) < 10:\n",
        "                        subset_items.append(item_id)\n",
        "                subset_items.extend([default_item] * (10 - len(subset_items)))\n",
        "                preds.append(subset_items)\n",
        "            predictions.extend(preds)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "predictions = get_predictions(model, test_loader)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW0B-lqOmSEN"
      },
      "source": [
        "Store our submission file with the predictions generated above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRACwkbBszix"
      },
      "source": [
        "SUBMISSION_PATH = f'{root_path}real_submission_10.csv'\n",
        "with open(SUBMISSION_PATH,'wb') as f:\n",
        "    preds_str = '\\n'.join([','.join([f'{y}' for y in x]) for x in predictions])\n",
        "    f.write(preds_str.encode())"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5JBBTo6BAvC"
      },
      "source": [
        "## References\n",
        "\n",
        "* [BERT Text Classification Using Pytorch](https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b)\n",
        "* [Multi-Task Learning with Pytorch and FastAI](https://towardsdatascience.com/multi-task-learning-with-pytorch-and-fastai-6d10dc7ce855)\n",
        "* [Configuring Google Colab Like A Pro](https://medium.com/@robertbracco1/configuring-google-colab-like-a-pro-d61c253f7573)\n",
        "* [Tuning a Multi-Task Pytorch Network on Fate Grand Order](https://towardsdatascience.com/tuning-a-multi-task-fate-grand-order-trained-pytorch-network-152cfda2e086)\n",
        "* [An Overview of Multi-Task Learning in Deep Neural Networks](https://ruder.io/multi-task/)"
      ]
    }
  ]
}