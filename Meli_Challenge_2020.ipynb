{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Meli_Challenge_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwVWQSxYF3si3gJz0YBnoC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanbeleno/meli-challenge-2020/blob/main/Meli_Challenge_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEgVHVKgSZWB"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "[Mercado Libre Data Challenge 2020](https://ml-challenge.mercadolibre.com/) requires to build a ML model to predict the next item to be bought by a user based on his/her history of searches and views.\n",
        "\n",
        "We start by installing the required libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmPve_Bretyi",
        "outputId": "5acf77a8-3afd-474a-e9aa-dede61a0cf97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ujson==4.0.1\n",
        "# !pip install transformers==3.4.0\n",
        "!pip install torch==1.7.0\n",
        "!pip install sentence-transformers==0.3.8\n",
        "! pip install fastprogress\n",
        "# https://github.com/UKPLab/sentence-transformers\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ujson==4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/84/e039c6ffc6603f2dfe966972d345d4f650a4ffd74b18c852ece645de12ac/ujson-4.0.1-cp36-cp36m-manylinux1_x86_64.whl (179kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 15.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 102kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 122kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 133kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 143kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 153kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 163kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 174kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 5.6MB/s \n",
            "\u001b[?25hInstalling collected packages: ujson\n",
            "Successfully installed ujson-4.0.1\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "Collecting sentence-transformers==0.3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/fd/0190080aa0af78d7cd5874e4e8e85f0bed9967dd387cf05d760832b95da9/sentence-transformers-0.3.8.tar.gz (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.4MB/s \n",
            "\u001b[?25hCollecting transformers<3.4.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.8) (3.2.5)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 29.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 43.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 46.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (20.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers==0.3.8) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers==0.3.8) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers==0.3.8) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers==0.3.8) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.4.0,>=3.1.0->sentence-transformers==0.3.8) (2.4.7)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.8-cp36-none-any.whl size=101996 sha256=2c9886613aabdce343f765e3407db11898a836005888bbfa44da88973fd0b390\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/ec/b3/d12cc8e4daf77846db6543033d3a5642f204c0320b15945647\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=09e53ce778d4f57e7983f82b7a1f4aa059474a2b7fb9991934d648e5b9b41e28\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.8 sentencepiece-0.1.94 tokenizers-0.8.1rc2 transformers-3.3.1\n",
            "Requirement already satisfied: fastprogress in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastprogress) (1.18.5)\n",
            "Tue Nov 17 02:30:58 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIK-1_eMWFpd"
      },
      "source": [
        "Make sure you don't get disconected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXIjuMUAWIsq",
        "outputId": "f6ff0c91-ee02-4eb4-fec2-ca34ad969101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXMQ4quYT7MW"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We store on Google Drive the item data, sample submission file, test and train dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ38pMXfPx7m",
        "outputId": "1575a0cf-2a8c-48e0-eccc-da02dfa707d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Setup Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/recursos_colab/meli_challenge_2020/'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VTFY-zbscgF"
      },
      "source": [
        "Run the code below just once, there is no need to download the files on Google Drive more than once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_T5yf_FiKwO",
        "outputId": "fb88e007-9129-49b3-cf44-c75d27558039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download the files and store them in Google Drive\n",
        "import requests\n",
        "file_urls = {\n",
        "    'test_dataset.jl.gz': 'https://meli-data-challenge.s3.amazonaws.com/2020/test_dataset.jl.gz',\n",
        "    'train_dataset.jl.gz': 'https://meli-data-challenge.s3.amazonaws.com/2020/train_dataset.jl.gz',\n",
        "    'item_data.jl.gz': 'https://meli-data-challenge.s3.amazonaws.com/2020/item_data.jl.gz',\n",
        "    'sample_submission.csv': 'https://meli-data-challenge.s3.amazonaws.com/2020/sample_submission.csv'\n",
        "}\n",
        "\n",
        "# Source: https://stackoverflow.com/q/62285313\n",
        "for file_name in file_urls:\n",
        "  r = requests.get(file_urls[file_name], stream = True)\n",
        "  with open(f'{root_path}{file_name}', \"wb\") as file:\n",
        "      for block in r.iter_content(chunk_size = 1024):\n",
        "          if block:\n",
        "              file.write(block)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9DZcJZLVzMW"
      },
      "source": [
        "## Data exploration\n",
        "\n",
        "The files have a Gzipped JSON Lines format and they use most of the RAM available on Google Colab (12GB), so I decided read the files line by line to save some RAM for model training usage. At this point, I'm only interested on two files: ```item_data.jl.gz``` and ```train_dataset.jl.gz```because they are used to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgaTjgYbZhhg"
      },
      "source": [
        "import gzip\n",
        "import ujson\n",
        "\n",
        "def print_first_lines(file_path, n=5):\n",
        "    \"\"\"Print the frist line of JSON Line file using identation of 4\"\"\"\n",
        "    with gzip.open(file_path,'rt') as f:\n",
        "        for index, line in enumerate(f):\n",
        "            data = ujson.loads(line)\n",
        "            print(ujson.dumps(data, indent=4))\n",
        "            if index >= n:\n",
        "              break\n",
        "\n",
        "def blocks(files, size=65536):\n",
        "    while True:\n",
        "        b = files.read(size)\n",
        "        if not b: break\n",
        "        yield b\n",
        "\n",
        "def print_num_lines(file_path):\n",
        "    \"\"\"Count the number of lines in a file\"\"\"\n",
        "    with gzip.open(file_path,'rb') as f:\n",
        "        print(sum(bl.decode().count(\"\\n\") for bl in blocks(f)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1m0bd5gYied"
      },
      "source": [
        "As we can see below, the training data is structured as a dictionary of purchases, searches and views associated with a item bought. We cannot see searches or purchases on the example below, but we know they exist because is shown on the [documentation](https://ml-challenge.mercadolibre.com/downloads) of the challenge. Also, we want to know the number of lines in this file because it's important to create DataLoader that will help us loading batches of records on training instead of loading all the dataset at the same time. There are ```413163``` lines in this file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT81O5wWYddE",
        "outputId": "88d947fd-7f80-4011-9f2c-65854f54b245",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print_first_line(f'{root_path}train_dataset.jl.gz')\n",
        "print_num_lines(f'{root_path}train_dataset.jl.gz')\n",
        "!wc -l gdrive/My Drive/recursos_colab/meli_challenge_2020/test_dataset.jl.gz\n",
        "!sed -n '$=' gdrive/My Drive/recursos_colab/meli_challenge_2020/train_dataset.jl.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"user_history\": [\n",
            "        {\n",
            "            \"event_info\": 1786148,\n",
            "            \"event_timestamp\": \"2019-10-19T11:25:42.444-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1786148,\n",
            "            \"event_timestamp\": \"2019-10-19T11:25:57.487-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": \"RELOGIO SMARTWATCH\",\n",
            "            \"event_timestamp\": \"2019-10-19T11:26:07.063-0400\",\n",
            "            \"event_type\": \"search\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T11:27:26.879-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T11:28:36.558-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T11:28:40.827-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T11:30:42.089-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:51:29.622-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:52:09.281-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:52:41.863-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:54:16.119-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:54:40.629-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T21:54:57.329-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-19T22:00:04.577-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-20T10:36:47.525-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-20T10:37:23.202-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-20T10:37:47.699-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-20T19:28:14.619-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        },\n",
            "        {\n",
            "            \"event_info\": 1615991,\n",
            "            \"event_timestamp\": \"2019-10-20T19:28:41.646-0400\",\n",
            "            \"event_type\": \"view\"\n",
            "        }\n",
            "    ],\n",
            "    \"item_bought\": 1748830\n",
            "}\n",
            "413162\n",
            "wc: gdrive/My: No such file or directory\n",
            "wc: Drive/recursos_colab/meli_challenge_2020/test_dataset.jl.gz: No such file or directory\n",
            "0 total\n",
            "sed: can't read gdrive/My: No such file or directory\n",
            "sed: can't read Drive/recursos_colab/meli_challenge_2020/train_dataset.jl.gz: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFzY_3XDZNAK"
      },
      "source": [
        "When the event type on the user history is a view or a purchase, then we have an ```event_info``` associated with an ```item_id``` on the file ```item_data.jl.gz``` that has the following information:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfccTW_5Q_Pw",
        "outputId": "5eb2e26a-83b1-467a-b17f-37e262ee0b87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print_first_lines(f'{root_path}item_data.jl.gz')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"item_id\": 111260,\n",
            "    \"title\": \"Casa Sola En Venta Con Gran Patio Solo Pago De Contado.\",\n",
            "    \"domain_id\": \"MLM-INDIVIDUAL_HOUSES_FOR_SALE\",\n",
            "    \"product_id\": null,\n",
            "    \"price\": \"1150000.00\",\n",
            "    \"category_id\": \"MLM170527\",\n",
            "    \"condition\": \"new\"\n",
            "}\n",
            "{\n",
            "    \"item_id\": 871377,\n",
            "    \"title\": \"Resident Evil Origins Collection Nintendo Switch (en D3gamer\",\n",
            "    \"domain_id\": \"MLM-VIDEO_GAMES\",\n",
            "    \"product_id\": \"15270800\",\n",
            "    \"price\": \"1392.83\",\n",
            "    \"category_id\": \"MLM151595\",\n",
            "    \"condition\": \"new\"\n",
            "}\n",
            "{\n",
            "    \"item_id\": 490232,\n",
            "    \"title\": \"Falda De Imitaci\\u00f3n Piel Negra\",\n",
            "    \"domain_id\": \"MLM-SKIRTS\",\n",
            "    \"product_id\": null,\n",
            "    \"price\": \"350.00\",\n",
            "    \"category_id\": \"MLM7697\",\n",
            "    \"condition\": \"new\"\n",
            "}\n",
            "{\n",
            "    \"item_id\": 1150706,\n",
            "    \"title\": \"Powercolor Red Devil Radeon Rx 580 8gb Gddr5\",\n",
            "    \"domain_id\": \"MLM-GRAPHICS_CARDS\",\n",
            "    \"product_id\": null,\n",
            "    \"price\": \"3200.00\",\n",
            "    \"category_id\": \"MLM9761\",\n",
            "    \"condition\": \"used\"\n",
            "}\n",
            "{\n",
            "    \"item_id\": 934912,\n",
            "    \"title\": \"Laptop Hp Nx6320 Core Duo Con Puerto Db9 Windows 7\",\n",
            "    \"domain_id\": \"MLM-NOTEBOOKS\",\n",
            "    \"product_id\": null,\n",
            "    \"price\": \"1599.00\",\n",
            "    \"category_id\": \"MLM1652\",\n",
            "    \"condition\": \"used\"\n",
            "}\n",
            "{\n",
            "    \"item_id\": 534737,\n",
            "    \"title\": \"Transmisor Fm Sin Hilos Bluetooth Reproductor De Mp3 Para Co\",\n",
            "    \"domain_id\": \"MLM-VEHICLE_ACCESSORIES\",\n",
            "    \"product_id\": null,\n",
            "    \"price\": \"470.00\",\n",
            "    \"category_id\": \"MLM92472\",\n",
            "    \"condition\": \"new\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-niKRTMqazOu"
      },
      "source": [
        "## Preparing the dataset\n",
        "\n",
        "Before creating the dataset, we need to map the domains to indices that can be used in a multi-task model. Also, we need to structure the item data in a dictionary to access that info faster to augment the Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVqakmtuxnbe"
      },
      "source": [
        "import gzip\n",
        "import ujson\n",
        "\n",
        "item_details = {}\n",
        "file_path = f'{root_path}item_data.jl.gz'\n",
        "with gzip.open(file_path,'rt') as f:\n",
        "    for index, line in enumerate(f):\n",
        "        data = ujson.loads(line)\n",
        "        item_id = data['item_id']\n",
        "        item_details[item_id] = data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf_9WGjiAkXc"
      },
      "source": [
        "Based on the idea that possibly not all the items in the set of item_details were bought in the training dataset. I will predict only the items and domains that appear in the training dataset. At the same time, I'm going to get some stats about the distribution of domains in the training set to know how oversample the minority of domains.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u954dcecBXpY"
      },
      "source": [
        "import gzip\n",
        "import ujson\n",
        "\n",
        "domain_map = {}\n",
        "categories_map = {}\n",
        "reduced_feature_map = {}\n",
        "domain_freq = {}\n",
        "top_items_per_domain = {}\n",
        "file_path = f'{root_path}train_dataset.jl.gz'\n",
        "with gzip.open(file_path,'rt') as f:\n",
        "  for line in f:\n",
        "    record = ujson.loads(line)\n",
        "    item_id = record['item_bought']\n",
        "    item = item_details[item_id]\n",
        "    domain_id = item['domain_id']\n",
        "    category_id = item['category_id']\n",
        "    \n",
        "    domain_freq[domain_id] = domain_freq.get(domain_id, 0) + 1\n",
        "\n",
        "    if domain_id not in domain_map:\n",
        "      domain_map[domain_id] = len(domain_map)\n",
        "\n",
        "    if category_id not in categories_map:\n",
        "      categories_map[category_id] = len(categories_map)\n",
        "\n",
        "    # Creating the dependencies in the prediction\n",
        "    if domain_id not in reduced_feature_map:\n",
        "      reduced_feature_map[domain_id] = {}\n",
        "    if item_id not in reduced_feature_map[domain_id]:\n",
        "      reduced_feature_map[domain_id][item_id] = len(reduced_feature_map[domain_id])\n",
        "    \n",
        "    # Finding the most bought items per domain\n",
        "    if domain_map[domain_id] not in top_items_per_domain:\n",
        "      top_items_per_domain[domain_map[domain_id]] = {}\n",
        "    top_items_per_domain[domain_map[domain_id]][item_id] = top_items_per_domain[domain_map[domain_id]].get(item_id, 0) + 1\n",
        "\n",
        "    # Replace domain text for its numerical identifier\n",
        "    #item_details[item_id]['domain_id'] = domain_map[domain_id]\n",
        "    #item_details[item_id]['category_id'] = categories_map[category_id]\n",
        "    #item_details[item_id]['feature_id'] = reduced_feature_map[domain_id][item_id]\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VvzIXInFGkM",
        "outputId": "4da89e9f-544a-4a8c-c059-471204de0146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'Items size: {len(item_details)}')\n",
        "print(f'Domains size: {len(domain_map)}')\n",
        "print(f'Categories size: {len(categories_map)}')\n",
        "features_sizes = [len(reduced_feature_map[domain]) for domain in reduced_feature_map]\n",
        "print(f'Min Features: {min(features_sizes)}')\n",
        "print(f'Max Features: {max(features_sizes)}')\n",
        "print(f'Average Features: {sum(features_sizes)/len(features_sizes)}')\n",
        "sorted_freqs = {k: v for k, v in sorted(domain_freq.items(), key=lambda item: item[1], reverse=True)}\n",
        "print(list(sorted_freqs.keys())[:5])\n",
        "print(list(sorted_freqs.values())[:25])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Items size: 2102277\n",
            "Domains size: 3214\n",
            "Categories size: 4001\n",
            "Min Features: 1\n",
            "Max Features: 2576\n",
            "Average Features: 20.20161792159303\n",
            "['MLB-CELLPHONES', 'MLB-SNEAKERS', 'MLB-SUPPLEMENTS', 'MLB-HEADPHONES', 'MLB-SMARTWATCHES']\n",
            "[25070, 14608, 9562, 9053, 7963, 4915, 4637, 4603, 4325, 4104, 3746, 3443, 3443, 3405, 3047, 2970, 2856, 2843, 2774, 2698, 2600, 2561, 2536, 2442, 2294]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXTSFigoV1Md",
        "outputId": "155a6534-5f2a-4f4a-cba2-40ddfb00d0f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "freq_values = list(domain_freq.values())\n",
        "freq_values.sort()\n",
        "percentile = freq_values[math.ceil(len(freq_values)*90/100)]\n",
        "print(f'P_90: {percentile}')\n",
        "\n",
        "plt.hist(freq_values, bins=100, range=(0, 500))\n",
        "plt.title(\"Histogram\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P_90: 235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyHCH5vicyKc"
      },
      "source": [
        "Oversample the 90% of the categories with fewer samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5S6N3G4dS-T",
        "outputId": "56ac5595-7d37-4806-f38c-d5c363a7c6d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gzip\n",
        "import ujson\n",
        "import random\n",
        "import math\n",
        "\n",
        "train_lines = []\n",
        "file_path = f'{root_path}train_dataset.jl.gz'\n",
        "size_threshold = 235\n",
        "with gzip.open(file_path,'rt') as f:\n",
        "  for line in f:\n",
        "    record = ujson.loads(line)\n",
        "    item_id = record['item_bought']\n",
        "    item = item_details[item_id]\n",
        "    domain_id = item['domain_id']\n",
        "\n",
        "    if domain_freq[domain_id] < size_threshold:\n",
        "      # Oversampling\n",
        "      num_samples = math.floor(size_threshold * 1.0 / domain_freq[domain_id])\n",
        "      sample_probability = (size_threshold * 1.0 / domain_freq[domain_id]) - num_samples\n",
        "      random_seed = random.uniform(0, 1)\n",
        "\n",
        "      if num_samples > 0:\n",
        "        for index in range(num_samples):\n",
        "          train_lines.append(line)\n",
        "\n",
        "      if random_seed <= sample_probability:\n",
        "        train_lines.append(line)\n",
        "    else:\n",
        "      train_lines.append(line)\n",
        "\n",
        "print(f'New dataset size: {len(train_lines)}')\n",
        "random.shuffle(train_lines)\n",
        "\n",
        "file_path = f'{root_path}train_dataset_oversampled.jl.gz'\n",
        "with gzip.open(file_path, 'wt') as f:\n",
        "  for index, line in enumerate(train_lines):\n",
        "    new_line = line.strip(' \\n\\r\\t')\n",
        "    if index == 0:\n",
        "      f.write(new_line)\n",
        "    else:\n",
        "      f.write(f'\\n{new_line}')\n",
        "train_lines = None\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New dataset size: 999790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcmorQsDMj_-",
        "outputId": "6e73549c-3261-4eca-b599-d6ef292cdeac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file_path = f'{root_path}train_dataset_oversampled.jl.gz'\n",
        "with gzip.open(file_path,'rt') as f:\n",
        "  for index, line in enumerate(f):\n",
        "    ujson.loads(line)\n",
        "print(index)\n",
        "#print_first_lines(f'{root_path}train_dataset_oversampled.jl.gz')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "999789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEUrMjDpyePX"
      },
      "source": [
        "**First dataset:** I'm planning to use only text as input, so I'll get the text on ```user_info```, when the ```event_type``` is a search and find the ```title``` on the ```item_data.jl.gz``` file when the ```event_type``` is a view or a purchase. Everything will be concatenated a single piece of text.\n",
        "\n",
        "**Random ideas for improvement:**\n",
        "* Remove duplicated ```item_id``` on the user_history\n",
        "* Create one classifier for each domain_id\n",
        "* Multi-task model for domain and for specific item\n",
        "* CRF on top to avoid prediction of items that does not exist in a domain\n",
        "* Oversample the 80% of the categories with fewer samples\n",
        "* Weighted mean for the text embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULJDoAHlcZ5L",
        "outputId": "c18681b1-fc39-4289-f26b-f199d90640ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import gzip\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import ujson\n",
        "#torch.multiprocessing.set_start_method('spawn')# good solution !!!!\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device: {device}')\n",
        "\n",
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, file_path, config):\n",
        "        self.file_path = file_path\n",
        "        self.config = config\n",
        "        self.sentence_model = SentenceTransformer('average_word_embeddings_glove.6B.300d')\n",
        "        self.sentence_model = self.sentence_model.to(device)\n",
        "        self.f = gzip.open(self.file_path, 'r')\n",
        "\n",
        "        # Source: https://github.com/pytorch/text/issues/130#issuecomment-510412877\n",
        "        '''\n",
        "        self.offset_dict = {}\n",
        "        with gzip.open(self.file_path,'rb') as f:\n",
        "            for index, line in enumerate(f):\n",
        "                offset = f.tell()\n",
        "                self.offset_dict[index] = offset\n",
        "        '''\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.config['data_size']\n",
        "        #return math.floor(self.config['data_size'] / self.config['batch_size'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Getting and preprocessing the inputs\"\"\"\n",
        "        #offset = self.offset_dict[idx]\n",
        "        if idx == 0:\n",
        "            self.f.close()\n",
        "            self.f = gzip.open(self.file_path, 'r')\n",
        "            self.f.seek(0)\n",
        "        response = {}\n",
        "\n",
        "        #with gzip.open(self.file_path,'rt') as f:\n",
        "        #   f.seek(offset)\n",
        "        line = self.f.readline()\n",
        "        raw_data = ujson.loads(line)\n",
        "        user_history = self.normalize_user_history(raw_data['user_history'])\n",
        "        item_bought = None\n",
        "        if 'item_bought' in raw_data:\n",
        "            item_bought = raw_data['item_bought']\n",
        "        views = []\n",
        "        searches = []\n",
        "        # The embedding size produced by DISTILLBERT is 768\n",
        "        #embedding_size = 768\n",
        "        embedding_size = 300\n",
        "        num_domains = 3214\n",
        "        avg_view_embeddings = np.zeros(embedding_size)\n",
        "        avg_search_embeddings = np.zeros(embedding_size)\n",
        "        domain_embeddings = np.zeros(num_domains)\n",
        "        if len(user_history) > 0:\n",
        "            sentence_embeddings = []\n",
        "            for item in user_history:\n",
        "                # Store the text in the search and the title from the items\n",
        "                # on purchases or views\n",
        "                if item['event_type'] == 'search':\n",
        "                    # I'm going to temporarily ignore the embeddings from\n",
        "                    # searches\n",
        "                    text = item['event_info']\n",
        "                    searches.append(text)\n",
        "                else:\n",
        "                    #text_embedding = item_details[item['event_info']]['text_embeddings']\n",
        "                    #sentence_embeddings.append(text_embedding)\n",
        "                    domain_id = item_details[item['event_info']]['domain_id']\n",
        "                    if domain_id in domain_map:\n",
        "                      domain_embeddings[domain_map[domain_id]] = domain_embeddings[domain_map[domain_id]] + 1\n",
        "                    text = item_details[item['event_info']]['title']\n",
        "                    views.append(text)\n",
        "            if len(views) > 0:\n",
        "              view_embeddings = self.sentence_model.encode(views)\n",
        "              avg_view_embeddings = self.embeddings_weighted_average(view_embeddings)\n",
        "            if len(searches) > 0:\n",
        "              search_embeddings = self.sentence_model.encode(searches)\n",
        "              avg_search_embeddings = self.embeddings_weighted_average(search_embeddings)\n",
        "        response['view_embeddings'] = avg_view_embeddings\n",
        "        response['search_embeddings'] = avg_search_embeddings\n",
        "        response['domain_embeddings'] = domain_embeddings\n",
        "        if item_bought:\n",
        "            item_data = item_details[item_bought]\n",
        "            domain_id = item_data['domain_id']\n",
        "            category_id = item_data['category_id']\n",
        "            response['item'] = torch.tensor(\n",
        "                reduced_feature_map[domain_id][item_bought], dtype=torch.long)\n",
        "            response['domain'] = torch.tensor(\n",
        "                domain_map[domain_id], dtype=torch.long)\n",
        "            response['category'] = torch.tensor(\n",
        "                categories_map[category_id], dtype=torch.long)\n",
        "        return response\n",
        "\n",
        "    def normalize_user_history(sefl, user_history):\n",
        "      # Remove duplicated views and searches that appear almost at the same time\n",
        "      new_user_history = []\n",
        "      last_item_id = ''\n",
        "      for item in user_history:\n",
        "        current_item_id = item['event_info']\n",
        "        if current_item_id != last_item_id:\n",
        "          new_user_history.append(item)\n",
        "        last_item_id = current_item_id\n",
        "      # We are only going to consider the last 20 events\n",
        "      return new_user_history[-20:]\n",
        "\n",
        "    def embeddings_weighted_average(self, embeddings):\n",
        "      # I'm going to use a logarithmic decrease in the importance of each\n",
        "      # view or search according to its recency\n",
        "      embeddings_size = embeddings.shape[0]\n",
        "      avg_embeddings = embeddings\n",
        "      if embeddings_size >= 1:\n",
        "        weights = [1.0 / math.log2(2 + index) for index in range(embeddings_size)]\n",
        "        normal_weigths = [float(w)/sum(weights) for w in weights]\n",
        "        # The last item in the embeddings is the most recent\n",
        "        normal_weigths = np.array(list(reversed(normal_weigths)))\n",
        "        avg_embeddings = embeddings * normal_weigths.reshape((normal_weigths.size, 1))\n",
        "        avg_embeddings = np.sum(avg_embeddings, axis=0)\n",
        "      return avg_embeddings\n",
        "        \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddlnU955UH_1"
      },
      "source": [
        "Get the data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00zSkp9YUJ2U"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# a simple custom collate function, just to show the idea\n",
        "def my_collate(batch):\n",
        "    searches = torch.from_numpy(np.array([item['search_embeddings'] for item in batch]))\n",
        "    views = torch.from_numpy(np.array([item['view_embeddings'] for item in batch]))\n",
        "    domain_views = torch.from_numpy(np.array([item['domain_embeddings'] for item in batch]))\n",
        "    items = [item['item'] for item in batch]\n",
        "    items = torch.LongTensor(items)\n",
        "    domains = [item['domain'] for item in batch]\n",
        "    domains = torch.LongTensor(domains)\n",
        "    return [searches, views, domain_views, items, domains]\n",
        "\n",
        "# a simple custom collate function, just to show the idea\n",
        "def my_collate_test(batch):\n",
        "    searches = torch.from_numpy(np.array([item['search_embeddings'] for item in batch]))\n",
        "    views = torch.from_numpy(np.array([item['view_embeddings'] for item in batch]))\n",
        "    domain_views = torch.from_numpy(np.array([item['domain_embeddings'] for item in batch]))\n",
        "    return searches, views, domain_views\n",
        "\n",
        "train_config = {\n",
        "    'data_size': 999790,\n",
        "    'batch_size': 64\n",
        "}\n",
        "ds = MultiTaskDataset(f'{root_path}train_dataset_oversampled.jl.gz', train_config)\n",
        "# If I set up a different value than 0 (main process) for the\n",
        "# num_workers parameter, then it stuck on a infinite loop\n",
        "train_loader = DataLoader(\n",
        "    ds, batch_size=train_config['batch_size'], num_workers=0,\n",
        "    collate_fn=my_collate, pin_memory=True, shuffle=True)\n",
        "\n",
        "\n",
        "test_config = {\n",
        "    'data_size': 177070,\n",
        "    'batch_size': 64\n",
        "}\n",
        "ds_test = MultiTaskDataset(f'{root_path}test_dataset.jl.gz', test_config)\n",
        "test_loader = DataLoader(\n",
        "    ds_test, batch_size=test_config['batch_size'], num_workers=0,\n",
        "    collate_fn=my_collate_test, pin_memory=True)\n",
        "\n",
        "#import time\n",
        "#start = time.process_time()\n",
        "#\n",
        "#import cProfile\n",
        "#cProfile.run('next(iter(train_loader))')\n",
        "#%timeit print(time.process_time() - start)\n",
        "# print(data)\n",
        "#import pdb; pdb.set_trace()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65wVy5Fs_WQr"
      },
      "source": [
        "## Creating the model\n",
        "\n",
        "The model is the ```bert-case-uncased``` version of BERT provided by HugginFaces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LymDLqH_yyG"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Creates a MultiTask model for classifications of domains and items based on\n",
        "    the same text\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #num_items = 2102277\n",
        "        #num_item_mappings = 2576\n",
        "        num_domains = 3214\n",
        "        #embedding_size = 768\n",
        "        embedding_size = 300\n",
        "\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        #self.dropout = nn.Dropout(0.1)\n",
        "        self.hidden_1 = nn.Linear(embedding_size*2 + num_domains, 512)\n",
        "        self.hidden_1_relu = nn.ReLU()\n",
        "        self.hidden_2 = nn.Linear(512, 256)\n",
        "        self.hidden_2_relu = nn.ReLU()\n",
        "        # Output layers\n",
        "        # Items: 41420 units\n",
        "        # Domains: 7894 units\n",
        "        self.output_domains = nn.Linear(256, num_domains)\n",
        "        #self.hidden_3 = nn.Linear(num_domains, 128)\n",
        "        #self.hidden_2_relu = nn.ReLU()\n",
        "        #self.output_items = nn.Linear(128, num_item_mappings)\n",
        "\n",
        "        # Define the softmax output\n",
        "        self.log_softmax_domains = nn.LogSoftmax(dim=1)\n",
        "        #self.log_softmax_items = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, views, searches, domain_views):\n",
        "        # Pass the input tensor through each of our operations\n",
        "        inputs = torch.cat((views, searches, domain_views), dim=1)\n",
        "        #x = self.dropout(inputs)\n",
        "        x = self.hidden_1(inputs)\n",
        "        x = self.hidden_1_relu(x)\n",
        "        x = self.hidden_2(x)\n",
        "        x = self.hidden_2_relu(x)\n",
        "\n",
        "        x_domains = self.output_domains(x)\n",
        "        y_domains = self.log_softmax_domains(x_domains)\n",
        "\n",
        "        #x_items = self.hidden_3(x_domains)\n",
        "        #x_items = self.hidden_2_relu(x_items)\n",
        "        #x_items = self.output_items(x_items)\n",
        "        #y_items = self.log_softmax_items(x_items)\n",
        "\n",
        "        return y_domains"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_tQfQHdI2qg"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ctQRdTdB9za",
        "outputId": "1ac6b73f-78b7-41f6-98fb-70fda6dac032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "from fastprogress import master_bar, progress_bar\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "\n",
        "# Define model\n",
        "model = MultiTaskModel()\n",
        "model = model.to(device)\n",
        "# Define the loss\n",
        "criterion = [nn.NLLLoss(), nn.NLLLoss()]\n",
        "criterion[0] = criterion[0].to(device)\n",
        "criterion[1] = criterion[1].to(device)\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "epochs = 2\n",
        "mb = master_bar(range(epochs))\n",
        "for epoch in mb:\n",
        "    running_loss = 0\n",
        "    print(f'Epoch: {epoch}')\n",
        "    start_time = time.time()\n",
        "    for views, searches, domain_views, items, domains in progress_bar(train_loader):\n",
        "        #if index % 50 == 0:\n",
        "        #    print(f'Batch load # {index} / {int(413163/256)}: {time.time() - start_time} seconds')\n",
        "\n",
        "        # Get features, items and domains\n",
        "        views = views.to(device)\n",
        "        searches = searches.to(device)\n",
        "        domain_views = domain_views.to(device)\n",
        "        items = items.to(device)\n",
        "        domains = domains.to(device)\n",
        "\n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output_domains = model(views.float(), searches.float(), domain_views.float())\n",
        "        #loss_items = criterion[0](output_items, items)\n",
        "        loss_domains = criterion[0](output_domains, domains)\n",
        "        #loss = loss_items + loss_domains\n",
        "        loss = loss_domains\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        start_time = time.time()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(train_loader)}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      \n",
              "    </div>\n",
              "    \n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='15622' class='' max='15622' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [15622/15622 41:55<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 4.937114958558005\n",
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='15622' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-608f5ce5f14b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain_views\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomains\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m#if index % 50 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#    print(f'Batch load # {index} / {int(413163/256)}: {time.time() - start_time} seconds')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-2a5828fb849a>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#   f.seek(offset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mujson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0muser_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_user_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mitem_bought\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected object or value"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7sbHHNbaIAT"
      },
      "source": [
        "Let's save our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfx3fG-3ZvcD"
      },
      "source": [
        "import torch\n",
        "\n",
        "model_path = f'{root_path}model-0.8.pth'\n",
        "torch.save(model.state_dict(), model_path)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "635LO4z7ZYBX"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "Before sending the answer to this challenge, we need to see the format for the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am8ROroUdvF4",
        "outputId": "b695d715-2602-42c8-94dd-415e00ee2036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with open(f'{root_path}sample_submission.csv','r') as f:\n",
        "    for index, line in enumerate(f):\n",
        "        if index < 4:\n",
        "            print(line)\n",
        "print(f'Number of lines: {index + 1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "654238,781750,558980,663439,1397720,1095079,798751,1141944,411021,138117\n",
            "\n",
            "462167,1511283,928291,1907892,66135,54134,1090655,700291,63494,613724\n",
            "\n",
            "2092880,1974491,1687910,371918,1659351,156119,578171,1407298,1378300,500637\n",
            "\n",
            "614011,509284,181629,1544217,267392,409673,755307,1621679,767644,617841\n",
            "\n",
            "Number of lines: 177070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUoAvkq0exYP"
      },
      "source": [
        "Now, we can save our file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvJOlnbnk_BA"
      },
      "source": [
        "# Optional\n",
        "model_path = f'{root_path}model-0.8.pth'\n",
        "model = MultiTaskModel()\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEPtgNSKVUXJ"
      },
      "source": [
        "def get_inverse_feature_map(features_map, domain_map):\n",
        "    inv_features_map = {}\n",
        "    for domain in features_map:\n",
        "        for item in features_map[domain]:\n",
        "            domain_id = domain_map[domain]\n",
        "            item_id = features_map[domain][item]\n",
        "            if domain_id not in inv_features_map:\n",
        "                inv_features_map[domain_id] = {}\n",
        "            if item_id not in inv_features_map[domain_id]:\n",
        "                inv_features_map[domain_id][item_id] = item\n",
        "    return inv_features_map\n",
        "\n",
        "inv_features_map = get_inverse_feature_map(reduced_feature_map, domain_map)\n",
        "\n",
        "# print(list(features_map['MLM-INDIVIDUAL_HOUSES_FOR_SALE'].keys())[0])\n",
        "# print(features_map['MLM-INDIVIDUAL_HOUSES_FOR_SALE'][111260])\n",
        "# print(domain_map['MLM-INDIVIDUAL_HOUSES_FOR_SALE'])\n",
        "# print(inv_features_map[1234])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcJEFFrkbHdk"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def get_predictions(model, data_loader):\n",
        "    model = model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for views, searches, domain_views in test_loader:\n",
        "            views = views.to(device)\n",
        "            searches = searches.to(device)\n",
        "            domain_views = domain_views.to(device)\n",
        "\n",
        "            domains = model(views.float(), searches.float(), domain_views.float())\n",
        "            #_, preds_items = torch.topk(items, 20)\n",
        "            _, preds_domains = torch.max(domains, dim=1)\n",
        "\n",
        "            #preds_items = preds_items.tolist()\n",
        "            preds = []\n",
        "            for index, domain in enumerate(preds_domains.tolist()):\n",
        "                subset_items = dict(Counter(top_items_per_domain[domain]).most_common(10))\n",
        "                subset_items = list(subset_items.keys())\n",
        "                while len(subset_items) < 10:\n",
        "                  subset_items.append(subset_items[0])\n",
        "                '''\n",
        "                default_item = list(inv_features_map[domain].values())[0]\n",
        "                subset_items = []\n",
        "                for item_candidate in preds_items[index]:\n",
        "                    item_id = inv_features_map[domain].get(item_candidate, None)\n",
        "                    if item_id and len(subset_items) < 10:\n",
        "                        subset_items.append(item_id)\n",
        "                subset_items.extend([default_item] * (10 - len(subset_items)))\n",
        "                '''\n",
        "                preds.append(subset_items)\n",
        "\n",
        "            predictions.extend(preds)\n",
        "    return predictions\n",
        "\n",
        "predictions = get_predictions(model, test_loader)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRACwkbBszix"
      },
      "source": [
        "with open(f'{root_path}real_submission_0.8.csv','wb') as f:\n",
        "    preds_str = '\\n'.join([','.join([f'{y}' for y in x]) for x in predictions])\n",
        "    f.write(preds_str.encode())"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5JBBTo6BAvC"
      },
      "source": [
        "## References\n",
        "\n",
        "* [BERT Text Classification Using Pytorch](https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b)\n",
        "* [Multi-Task Learning with Pytorch and FastAI](https://towardsdatascience.com/multi-task-learning-with-pytorch-and-fastai-6d10dc7ce855)\n",
        "* [Configuring Google Colab Like A Pro](https://medium.com/@robertbracco1/configuring-google-colab-like-a-pro-d61c253f7573)\n",
        "* [Tuning a Multi-Task Pytorch Network on Fate Grand Order](https://towardsdatascience.com/tuning-a-multi-task-fate-grand-order-trained-pytorch-network-152cfda2e086)\n",
        "* [An Overview of Multi-Task Learning in Deep Neural Networks](https://ruder.io/multi-task/)"
      ]
    }
  ]
}